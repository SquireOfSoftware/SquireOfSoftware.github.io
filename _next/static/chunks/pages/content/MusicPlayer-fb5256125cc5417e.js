(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[671],{2674:function(e,t,n){"use strict";n.r(t),n.d(t,{default:function(){return d}});n(7294);var a=n(1587),r=n.n(a),s=n(4593),o=n.n(s),i=n(5893);function d(e){return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)("p",{children:"Imagine that you are hosting a party, you're busy eating cheetos and doritos with your friends when you are suddenly interrupted by your neighbour asking you to turn the music down. But how do you do that when your fingers are all grimed up with chip dust?"}),(0,i.jsx)("p",{children:"You* can use a hand gesture trained neural network so that you can just control your music with a simple swipe of your hand. And so:"}),(0,i.jsx)("p",{children:"Music too loud? Just lower your hand and the music will drop in volume"}),(0,i.jsx)("p",{children:"Music too soft? Just raise your hand and the music will increase in volume"}),(0,i.jsx)("p",{children:"Not a fan of the current song? Just swipe right and the music player will skip your song"}),(0,i.jsx)("p",{children:"Previous song gave you chills? Just swipe left and the music player will replay your song"}),(0,i.jsx)("p",{children:(0,i.jsx)("sup",{children:"* Besides using a digital assistant"})}),(0,i.jsx)("p",{children:"At least...that was the dream..."}),(0,i.jsx)("p",{children:"What our 3 person group ended up producing was a neural network that would understand one of these four hand gestures 47.5% of the time (swiping right and down were the most understood gestures)."}),(0,i.jsx)("h3",{className:o().sticky_heading,children:"How did we set out to build this?"}),(0,i.jsx)("p",{children:"We first had to plan how we would architect the neural network. Given our limited knowledge in the topic, we opted for a Back Propagation design:"}),(0,i.jsx)("img",{src:"images/neural_net/Neural Network design.png",className:r().image}),(0,i.jsx)("p",{children:"From here, we would use some sort of device to capture as many hand gestures and motions of people moving their hands in a particular direction and then feed this data into the Neural Network to hopefully teach it how to understand each of these gestures."}),(0,i.jsx)("p",{children:"From here we mapped out the maths that we would need to get this system to start learning from the inputs that we were providing to the neural net:"}),(0,i.jsx)("img",{src:"images/neural_net/Neural Network implementation.png",className:r().image}),(0,i.jsx)("p",{children:"We had a bias at the front to increase the fit of the predication against the data better."}),(0,i.jsx)("p",{children:"We decided to run a bipolar sigmoidal function as our activation function...because...well we didn't know any better."}),(0,i.jsx)("p",{children:"And we only went 2 nodes deep, since this was our first neural network, we wanted to keep it simple."}),(0,i.jsx)("p",{children:"We also decided to split the dataset into the training set and the validation set. Where the training set is all the data that the neural network would see and conform itself against, whilst the validation set is all the data that the neural network has not seen yet and will be used to confirm that the network is learning the correct things."}),(0,i.jsx)("p",{children:"We would then proceed to run a training set through the network, measure its assessment against what the training set was classified as (so we would run a left swipe through the network, check the outputs and see how accurate it was to classification of the training set)."}),(0,i.jsx)("p",{children:'To ensure that our network did not "over train" on the training data set, that is, to ensure that the network was actually learning and not just memorising the right values, we would periodically give the network a few entries from the validation dataset and see what the prediction is from the network at that given time.'}),(0,i.jsx)("p",{children:'And how "wrong" the network would get the validation set would form our error rate per dataset "cycle".'}),(0,i.jsx)("p",{children:'And if the verification "error" rate would start going up, it would be an indicator that our network was beginning to get over trained and we would have to stop the training process.'}),(0,i.jsx)("h3",{className:o().sticky_heading,children:"How did we implement this design?"}),(0,i.jsx)("p",{children:"We built this project in Matlab and we used a Leap Motion controller to capture our hand gestures."}),(0,i.jsx)("p",{children:"Once we got our development devices, we then started trying to capture hand gestures from all types of people and hand sizes. The more data that we could capture the more accurate our network would become because of all the varied ways that people could move their hands."}),(0,i.jsx)("p",{children:"Here is a sample hand gesture of a swipe left gesture."}),(0,i.jsx)("img",{src:"images/neural_net/Sample Neural Network capture.gif"}),(0,i.jsx)("p",{children:"The Leap Motion controller could pick up all 5 fingers and we decided to make the sample 60 seconds of a hand performing the gesture (about 1 sample per minute). This comes out to be about 300 data points per gesture and we would feed this directly into the network for it to learn."}),(0,i.jsx)("p",{children:"Probably the most difficult part was actually the capture, as it often took upwards of 45 minutes of just constantly recording of single person swiping hand gestures over and over again. We recorded about 1400 hand gestures across 6 different people."}),(0,i.jsx)("p",{children:"Of the 1400 recordings, we had about 300+ recording per hand gesture. We then split this up into 1000 gestures (which is 250 per gesture), 200 validation recordings and 200+ for the final test gestures (gestures that the network has not seen or validated against before)."}),(0,i.jsx)("p",{children:"The math though difficult (mainly in ensuring we had the right set up), was fairly easy to replicate and reset everything once you had the correct formulas established."}),(0,i.jsx)("h3",{className:o().sticky_heading,children:"Our results"}),(0,i.jsx)("p",{children:"For our over trained network, we obtained 78% across all four gestures."}),(0,i.jsx)("img",{src:"images/neural_net/Training results.png",className:r().image}),(0,i.jsx)("p",{children:"For our under trained network, we obtained 47.5% across all four gestures. But we really needed more data to make this network work."}),(0,i.jsx)("img",{src:"images/neural_net/Training results 2.png",className:r().image}),(0,i.jsx)("h3",{className:o().sticky_heading,children:"Lessons Learnt"}),(0,i.jsx)("img",{src:"images/neural_net/Lessons learnt.png",className:r().image}),(0,i.jsx)("p",{children:"We played around with different neuron sizes to see how it would learn differently, we found that the larger the set of neurons on the second layer, the longer the training would require and the slower that the network would learn. So we settled for 35 neurons on the second layer to tradeoff between speed and accuracy."}),(0,i.jsx)("p",{children:"We also found that we could not put in the raw data into the network, we actually had to normalise it otherwise the math ended up neutralising a lot of the finer details in the gestures. So we had to shift all the data up by a certain offset so that they were above zero."}),(0,i.jsx)("p",{children:"We also found out (late in the training) that the Leap Motion Controller would sometimes screw up the identification of each of the fingers, resulting in fingers that would jump each other. We discovered this very late in the training process and probably contributed to the low identification rate."}),(0,i.jsx)("p",{children:"And we also found that we could have probably reduced the input space to speed up the training, we were tracking the fingers, but instead we could have tracked the palm and used that to record our data. So that would have just been 60 samples of the palm instead of the 300 for the 5 fingers."}),(0,i.jsx)("img",{src:"images/neural_net/Reflections.png",className:r().image}),(0,i.jsxs)("p",{children:["For the full source code on how this worked and the resulting Neural Net that we had trained, you can go to this link"," ",(0,i.jsx)("a",{href:"https://github.com/SquireOfSoftware/NNFL/tree/master/Project",target:"_blank",children:"here"}),"."]})]})}},4675:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/content/MusicPlayer",function(){return n(2674)}])},1587:function(e){e.exports={image:"MusicPlayer_image__dWL3Y"}},4593:function(e){e.exports={sticky_heading:"Page_sticky_heading__yLneF"}}},function(e){e.O(0,[774,888,179],(function(){return t=4675,e(e.s=t);var t}));var t=e.O();_N_E=t}]);